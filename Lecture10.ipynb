{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 101 & Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with TensorFlow\n",
    "* The benefits of using TensorFlow include:\n",
    "    * Python API\n",
    "    * Portability: can be used on multiple CPUs or GPUs as well as on mobile devices\n",
    "    * Flexibility: can run on different devices e.g. Raspberry Pi, Android, iOS, Windows, Linux\n",
    "    * Visualization: visualize the training process via TensorBoard\n",
    "    * Checkpoints: manage trained models\n",
    "    * Auto-differentiation\n",
    "    * Large community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph and Sessions\n",
    "* In TensorFlow, the definition of computations is separated from their execution. \n",
    "* First, we specify the operations by building a data flow graph in Python. Next, TensorFlow runs the graph with a Session using optimized C++ code. Let's import tensorflow first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\" # choose which GPU you want to use\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import urllib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph\n",
    "* A computational graph is a series of TensorFlow operations arranged into a graph. The graph is composed of two types of objects.\n",
    "    * tf.Operation: The nodes of the graph. Operations describe calculations that consume and produce tensors.\n",
    "    * tf.Tensor: The edges in the graph. These represent the values that will flow through the graph. Most TensorFlow functions return tf.Tensors.\n",
    "        * Notes: tf.Tensors do not have values, they are just handles to elements in the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session\n",
    "* To evaluate tensors, instantiate a tf.Session object, informally known as a session. \n",
    "* A session encapsulates the state of the TensorFlow runtime, and runs TensorFlow operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"const3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"const4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# build a naive graph\n",
    "a_tensor = tf.constant(3., name=\"const3\")\n",
    "b_tensor = tf.constant(4., name=\"const4\")\n",
    "out_tensor = tf.add(a_tensor, b_tensor)\n",
    "print(a_tensor, b_tensor, out_tensor, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice that printing the tensors does not output the values 3.0, 4.0, and 7.0 as you might expect. \n",
    "* The above statements only build the computation graph. These tf.Tensor objects just represent the results of the operations that will be run.\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/tensor_op.png' width='200'>\n",
    "* We need a tf.Session to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 3.0 \n",
      "b = 4.0 \n",
      "c = 7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() # create a session\n",
    "a, b, c = sess.run([a_tensor, b_tensor, out_tensor])\n",
    "print(\"a = {} \\nb = {} \\nc = {}\".format(a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "* A tensor is a generalization of vectors and matrices to potentially higher dimensions.\n",
    "* When writing a TensorFlow program, the main object you manipulate and pass around is the tf.Tensor. \n",
    "* A tf.Tensor object represents a partially defined computation that will eventually produce a value. \n",
    "* TensorFlow programs work by first building a graph of tf.Tensor objects, detailing how each tensor is computed based on the other available tensors and then by running parts of this graph to achieve the desired results.\n",
    "* A tf.Tensor has the following properties:\n",
    "    * a data type (tf.float32, tf.int32, or tf.string, for example)\n",
    "    * a shape\n",
    "* The rank of a tensor refers to the number of dimensions it has.\n",
    "* The shape of a tensor speficies the array's length along each dimension.\n",
    "    * 3. a rank 0 tensor; a scalar with shape [],\n",
    "    * [1., 2., 3.] a rank 1 tensor; a vector with shape [3]\n",
    "    * [[1., 2., 3.], [4., 5., 6.]] a rank 2 tensor; a matrix with shape [2, 3]\n",
    "    * [[[1., 2., 3.]], [[7., 8., 9.]]] a rank 3 tensor with shape [2, 1, 3]\n",
    "* Some types of tensors are special. \n",
    "* The main ones are:\n",
    "    * tf.constant\n",
    "    * tf.Variable\n",
    "    * tf.placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.constant\n",
    "* We can create constants by passing lists or constants into the tf.constant function.\n",
    "    * tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vector:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"matrix:0\", shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# constant of 1d tensor (vector)\n",
    "a = tf.constant([2, 2], dtype=tf.int32, name=\"vector\")\n",
    "# constant of 2x2 tensor (matrix)\n",
    "b = tf.constant([[0, 1], [2, 3]], name=\"matrix\")\n",
    "print(a, b, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also create tensors of a specific value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros_matrix:0\", shape=(2, 3), dtype=int32)\n",
      "Tensor(\"ones_matrix:0\", shape=(2, 3), dtype=int32)\n",
      "Tensor(\"zeros_like_matrix:0\", shape=(3, 2), dtype=float32)\n",
      "Tensor(\"ones_like_matrix:0\", shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# a matrix with filled zeros\n",
    "c = tf.zeros([2, 3], tf.int32, name=\"zeros_matrix\") # [[0, 0, 0], [0, 0, 0]]\n",
    "# a matrix with filled ones\n",
    "d = tf.ones([2, 3], tf.int32, name=\"ones_matrix\") #  [[1, 1, 1], [1, 1, 1]]\n",
    "\n",
    "# create a tensor filled zeros/ones, with shape and type as input_tensor\n",
    "input_tensor = tf.constant([[1,1], [2,2], [3,3]], dtype=tf.float32)\n",
    "e = tf.zeros_like(input_tensor, name=\"zeros_like_matrix\")  #  [[0, 0], [0, 0], [0, 0]]\n",
    "f = tf.ones_like(input_tensor, name=\"ones_like_matrix\") # [[1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "print(c, d, e, f, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Variables\n",
    "* Unlike a constant, a variable can be assigned to, so its value can be changed. Also, a constant's value is stored on the graph, whereas a variable's value is stored seperately. \n",
    "* To declare a variable, we create a instance of tf.get_variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'vector_1:0' shape=(3,) dtype=float32_ref>\n",
      "<tf.Variable 'matrix_1:0' shape=(5, 3) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# create a variable of vector\n",
    "vec_var = tf.get_variable(name=\"vector\", shape=[3],\n",
    "                          initializer=tf.ones_initializer)\n",
    "# create a variable of matrix\n",
    "mat_var = tf.get_variable(name=\"matrix\", shape=[5, 3],\n",
    "                          initializer=tf.random_normal_initializer)\n",
    "\n",
    "print(vec_var, mat_var, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Or we can create variables by calling tf.Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'scalar:0' shape=() dtype=int32_ref>\n",
      "Tensor(\"Assign:0\", shape=(), dtype=int32_ref)\n"
     ]
    }
   ],
   "source": [
    "# instance of `tf.Variable`\n",
    "var = tf.Variable(2, name=\"scalar\")\n",
    "\n",
    "# we can assign new value to a variable\n",
    "var_times_two = var.assign(var * 2) # an operation that assigns value var*2 to var\n",
    "print(var, var_times_two, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5c9be7902855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the following code will casue error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "# constant value is not changable\n",
    "# the following code will casue error\n",
    "c = tf.constant(0.)\n",
    "c.assign(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since constraint mentiond above, all fixed value should be as type tf.constant, while trainable weights should be as type tf.Variable\n",
    "* Before you can use a variable, it must be initialized. If you are programming in the low-level TensorFlow API (that is, you are explicitly creating your own graphs and sessions), you must explicitly initialize the variables.\n",
    "* To initialize all trainable variables in one go, before training starts, call tf.global_variables_initializer(). This function returns a single operation responsible for initializing all variables in the tf.GraphKeys.GLOBAL_VARIABLES collection. Running this operation initializes all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_init_op = tf.global_variables_initializer() # an operation\n",
    "sess.run(variable_init_op) # initialize the variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.placeholder\n",
    "* As it stands, this graph is not especially interesting because it always produces a constant result. \n",
    "* A graph can be parameterized to accept external inputs, known as placeholders. \n",
    "* A placeholder is a promise to provide a value later, like a function argument.\n",
    "    * tf.placeholder(dtype, shape=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a_placeholder = tf.placeholder(tf.float32, shape=[None, 3], name=\"a\")\n",
    "print(a_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A placeholder should be provided a value when executed by tf.Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "a = sess.run(a_placeholder, feed_dict={a_placeholder: [[1, 2, 3], [4, 5, 6]]})\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an example to summarize above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a basic graph that demos the basic tensorflow concepts\n",
    "with tf.Graph().as_default() as g:\n",
    "    # a constant tensor with rank = 0\n",
    "    scalar_tensor = tf.constant(5., name=\"scalar\") \n",
    "    \n",
    "    # a vector tensor with rank = 1, and filled with random values\n",
    "    vector_tensor = tf.random_normal(shape=[5], name=\"vector\") \n",
    "    \n",
    "    # tensorflow supports broadcast\n",
    "    broadcast_with_scalar = vector_tensor + scalar_tensor \n",
    "    \n",
    "    # use placeholder to get values in runtime\n",
    "    x_input = tf.placeholder(tf.float32, shape=[None, 5], name=\"input\")\n",
    "    feature_dims = x_input.shape[1]\n",
    "    \n",
    "    # a matrix variable with rank = 2.\n",
    "    matrix_variable = tf.get_variable(\"matrix\",\n",
    "                                      shape=[feature_dims, 2],\n",
    "                                      initializer=tf.ones_initializer) \n",
    "    mul_with_matrix = tf.matmul(x_input, matrix_variable, name=\"output\")\n",
    "    \n",
    "    var_init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scalar]\n",
      " 5.0 \n",
      "[vector]\n",
      " [ 0.5607612   0.13617027  0.03677087  0.72220516 -1.4275804 ] \n",
      "[broadcast]\n",
      " [5.5607615 5.1361704 5.036771  5.722205  3.5724196]\n",
      "[input]\n",
      " [[1. 3. 4. 1. 1.]\n",
      " [4. 3. 3. 0. 1.]\n",
      " [3. 2. 1. 0. 3.]\n",
      " [4. 1. 1. 0. 2.]\n",
      " [1. 0. 2. 0. 2.]] \n",
      "[matrix]\n",
      " [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]] \n",
      "[output]\n",
      " [[10. 10.]\n",
      " [11. 11.]\n",
      " [ 9.  9.]\n",
      " [ 8.  8.]\n",
      " [ 5.  5.]]\n"
     ]
    }
   ],
   "source": [
    "feed_data = np.random.randint(5, size=[5, 5])\n",
    "\n",
    "# Under the scope of session, we can run the value of tensor in default graph\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(var_init_op) # must initialize the variables\n",
    "    \n",
    "    scalar, vector, broadcast = sess.run([scalar_tensor,\n",
    "                                          vector_tensor,\n",
    "                                          broadcast_with_scalar])\n",
    "    print(\"[scalar]\\n {} \\n[vector]\\n {} \\n[broadcast]\\n {}\".format(scalar,\n",
    "                                                                    vector,\n",
    "                                                                    broadcast))\n",
    "    \n",
    "    x, m, out = sess.run([x_input, matrix_variable, mul_with_matrix],\n",
    "                         feed_dict={x_input: feed_data})\n",
    "    print(\"[input]\\n {} \\n[matrix]\\n {} \\n[output]\\n {}\".format(x, m, out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a Graph with TensorBoard\n",
    "* The computations you'll use TensorFlow for - like training a massive deep neural network - can be complex and confusing. \n",
    "* To make it easier to understand, debug, and optimize TensorFlow programs, TF included a suite of visualization tools called TensorBoard.\n",
    "* You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it.\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/tensorboard.png' width='700'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Graph\n",
    "* Create a writer with tf.summary.FileWriter to write the graph into file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = \"graphs/demo\"\n",
    "os.makedirs(graph_dir)\n",
    "with tf.Graph().as_default() as g:\n",
    "    const_a = tf.constant(1., shape=[1, 5], name=\"const_a\")\n",
    "    const_b = tf.add(const_a, 5, name=\"const_b\")\n",
    "    var_c = tf.get_variable(\"var_c\", shape=[5, 3])\n",
    "    const_d = tf.matmul(const_b, var_c, name=\"const_d\")\n",
    "    # create a writer \n",
    "    writer = tf.summary.FileWriter(graph_dir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Tensorboard\n",
    "* To run TensorBoard, use the following command: \n",
    "    * tensorboard --logdir=path/to/log-directory\n",
    "* where logdir points to the directory where the FileWriter serialized its data.\n",
    "* If this logdir directory contains subdirectories which contain serialized data from separate runs, then TensorBoard will visualize the data from all of those runs. Once TensorBoard is running, navigate your web browser to localhost:6006 to view the TensorBoard.\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/demo-tensorboard.png' width='300'>\n",
    "* TensorBoard provides more than that. You can check [here](https://www.tensorflow.org/guide/summaries_and_tensorboard) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very Very important!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Restore checkpoints\n",
    "* Training a deep learning model may take a few hours or even a few days. \n",
    "* The learned weights should be saved periodically so that you can restore for further applications. In TensorFlow, all trainable variables can be saved in checkpoints - a binary file that map variable names to tensor values.\n",
    "* In this part, we will guide you how to save and restore the model. TensorFlow provides a superb class tf.train.Saver to do this work. \n",
    "* Its constructor adds save and restore ops to the graph for all, or a specified list, of the variables in the graph. The Saver object provides methods to run these ops, specifying paths for the checkpoint files to write to or read from.\n",
    "* You can check [here](https://www.tensorflow.org/guide/saved_model) for more than that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save variables\n",
    "* Create a Saver with tf.train.Saver() to manage all variables in the model. \n",
    "* The following cell shows how to call the tf.train.Saver.save method to save variables to checkpoint files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graph]\n",
      "Tensor(\"Const:0\", shape=(5,), dtype=int32)\n",
      "<tf.Variable 'var_b:0' shape=(5,) dtype=int32_ref>\n",
      "Tensor(\"add:0\", shape=(5,), dtype=int32)\n",
      "<tf.Variable 'var_d:0' shape=(3,) dtype=float32_ref>\n",
      "\n",
      "[Trainable variables]\n",
      "<tf.Variable 'var_b:0' shape=(5,) dtype=int32_ref>\n",
      "<tf.Variable 'var_d:0' shape=(3,) dtype=float32_ref>\n",
      "\n",
      "[Value]\n",
      "[2 2 2 2 2]\n",
      "[0 0 0 0 0]\n",
      "[2 2 2 2 2]\n",
      "[1. 1. 1.]\n",
      "\n",
      "[Model saved in path: checkpoints/demo/model.ckpt]\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = \"checkpoints/demo\"\n",
    "os.makedirs(ckpt_dir)\n",
    "with tf.Graph().as_default() as g:\n",
    "    const_a = tf.constant(2, tf.int32, [5])\n",
    "    var_b = tf.get_variable(\"var_b\", dtype=tf.int32, shape=[5],\n",
    "                            initializer=tf.zeros_initializer) # variable\n",
    "    const_c = var_b + const_a\n",
    "    var_d = tf.get_variable(\"var_d\", shape=[3],\n",
    "                            initializer=tf.ones_initializer) # variable\n",
    "    \n",
    "    print(\"[Graph]\", const_a, var_b, const_c, var_d, sep=\"\\n\")\n",
    "    print(\"\\n[Trainable variables]\", *tf.trainable_variables(), sep=\"\\n\")\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    # Declare a saver object to save checkpoints\n",
    "    saver = tf.train.Saver() \n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Do some works with the model\n",
    "    a, b, c, d = sess.run([const_a, var_b, const_c, var_d])\n",
    "    print(\"\\n[Value]\", a, b, c, d, sep=\"\\n\")\n",
    "    \n",
    "    # Save the variables to disk\n",
    "    save_path = saver.save(sess, os.path.join(ckpt_dir, \"model.ckpt\"))\n",
    "    print(\"\\n[Model saved in path: {}]\".format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect variables in checkpoints\n",
    "* This is a **useful function to debug**. Sometimes you may notice that you have some conflict between your model and checkpoints. \n",
    "* That's why you need this function to insepct what you stored in the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_b (DT_INT32) [5]\n",
      "var_d (DT_FLOAT) [3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "# tensor_name: Name of the tensor in the checkpoint file to print. \n",
    "# all_tensors: Boolean indicating whether to print all tensors.\n",
    "# all_tensor_names: Boolean indicating whether to print all tensor names.\n",
    "print_tensors_in_checkpoint_file(save_path,\n",
    "                                 tensor_name=\"\",\n",
    "                                 all_tensors=\"\",\n",
    "                                 all_tensor_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore variables\n",
    "* The tf.train.Saver object not only saves variables to checkpoint files, it also restores variables. \n",
    "* $\\color{red}{\\text{Note}}$ that when you restore variables you do not have to initialize them beforehand. \n",
    "* For example, the following snippet demonstrates how to call the tf.train.Saver.restore method to restore variables from the checkpoint files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/demo/model.ckpt\n",
      "\n",
      "[Value]\n",
      "[2 2 2 2 2]\n",
      "[0 0 0 0 0]\n",
      "[2 2 2 2 2]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    saver.restore(sess, save_path)\n",
    "    a, b, c, d = sess.run([const_a, var_b, const_c, var_d])\n",
    "    print(\"\\n[Value]\", a, b, c, d, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"checkpoints/demo/model.ckpt\"\n",
      "all_model_checkpoint_paths: \"checkpoints/demo/model.ckpt\"\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/demo/model.ckpt\n",
      "\n",
      "[Value]\n",
      "[2 2 2 2 2]\n",
      "[0 0 0 0 0]\n",
      "[2 2 2 2 2]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# more robust\n",
    "with tf.Session(graph=g) as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    print(ckpt)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    a, b, c, d = sess.run([const_a, var_b, const_c, var_d])\n",
    "    print(\"\\n[Value]\", a, b, c, d, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "### Dataset and Iterator\n",
    "* The tf.data API enables you to build complex input pipelines from simple, reusable pieces. \n",
    "* For example, the pipeline for an image model might aggregate data from files in a distributed file system, apply random perturbations to each image, and merge randomly selected images into a batch for training. The pipeline for a text model might involve extracting symbols from raw text data, converting them to embedding identifiers with a lookup table, and batching together sequences of different lengths. \n",
    "* The tf.data API makes it easy to deal with large amounts of data, different data formats, and complicated transformations.\n",
    "* The tf.data API introduces two new abstractions to TensorFlow:\n",
    "    * A tf.data.Dataset represents a sequence of elements, in which each element contains one or more Tensor objects. \n",
    "        * For example, in an image pipeline, an element might be a single training example, with a pair of tensors representing the image data and a label. \n",
    "        * There are two distinct ways to create a dataset:\n",
    "            * Creating a source (e.g. Dataset.from_tensor_slices()) constructs a dataset from one or more tf.Tensor objects.\n",
    "            * Applying a transformation (e.g. Dataset.batch()) constructs a dataset from one or more tf.data.Dataset objects.\n",
    "    * A tf.data.Iterator provides the main way to extract elements from a dataset. \n",
    "        * The operation returned by Iterator.get_next() yields the next element of a Dataset when executed, and typically acts as the interface between input pipeline code and your model. \n",
    "        * The simplest iterator is a \"one-shot iterator\", which is associated with a particular Dataset and iterates through it once. \n",
    "        * For more sophisticated uses, the Iterator.initializer operation enables you to reinitialize and parameterize an iterator with different datasets, so that you can, for example, iterate over training and validation data multiple times in the same program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "## Pseudo dataset\n",
    "dataset_size = 20\n",
    "# 20 examples, each example has 5 features\n",
    "data = np.random.rand(dataset_size, 5)\n",
    "# this dataset has 3 labels\n",
    "label = np.random.randint(low=0, high=3, size=dataset_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Original dataset] \n",
      " <TensorSliceDataset shapes: ((5,), ()), types: (tf.float64, tf.int64)>\n",
      "\n",
      "[Transformed dataset] \n",
      " <BatchDataset shapes: ((?, 5), (?,)), types: (tf.float64, tf.int64)>\n",
      "\n",
      "[Iterator] \n",
      " <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7f1fe816e828>\n",
      "\n",
      "[Elements extracted by iterator] \n",
      " Tensor(\"IteratorGetNext:0\", shape=(?, 5), dtype=float64) \n",
      " Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 7\n",
    "\n",
    "## Create a `dataset` by `from_tensor_slices`\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "print(\"[Original dataset] \\n\", training_dataset)\n",
    "training_dataset = training_dataset.batch(batch_size)\n",
    "print(\"\\n[Transformed dataset] \\n\", training_dataset)\n",
    "\n",
    "## Create a `iterator` to extract elements from `dataset`\n",
    "training_iterator = training_dataset.make_initializable_iterator()\n",
    "x_input, y_label = training_iterator.get_next()\n",
    "print(\"\\n[Iterator] \\n\", training_iterator)\n",
    "print(\"\\n[Elements extracted by iterator] \\n\", x_input, \"\\n\", y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After creating tensor of x_input and y_label, we can build a graph for it.\n",
    "* Here we skip the model building process, we demonstrates how will the tensors display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 batch - 7 examples\n",
      "[[0.69507032 0.25118953 0.61266071 0.44003168 0.30113935]\n",
      " [0.87280118 0.51761585 0.38677478 0.05839929 0.30306418]\n",
      " [0.47897569 0.05592283 0.27137109 0.96620529 0.29255599]\n",
      " [0.3484134  0.25219133 0.82599493 0.40188843 0.84520525]\n",
      " [0.14570427 0.85133326 0.67677334 0.61922411 0.02308789]\n",
      " [0.21940755 0.40837291 0.06455535 0.2121623  0.39840965]\n",
      " [0.14568174 0.28880465 0.71695792 0.81745312 0.41030093]] [0 1 2 1 0 2 1]\n",
      "2 batch - 7 examples\n",
      "[[0.94010847 0.04593886 0.11948305 0.09974837 0.51419986]\n",
      " [0.6075151  0.19458069 0.12099634 0.25292659 0.38429445]\n",
      " [0.20214036 0.55046687 0.56806782 0.0400243  0.30312837]\n",
      " [0.55660472 0.09050287 0.6530809  0.66135675 0.83914861]\n",
      " [0.5637909  0.37355936 0.04997498 0.6048784  0.9006687 ]\n",
      " [0.47649245 0.58965803 0.49991578 0.55757594 0.97519476]\n",
      " [0.40011013 0.22378639 0.21209775 0.97276286 0.70211188]] [1 1 2 1 1 1 0]\n",
      "3 batch - 6 examples\n",
      "[[0.00123643 0.40330752 0.72430283 0.43790874 0.65020544]\n",
      " [0.50619529 0.35106484 0.1908261  0.97124277 0.70315201]\n",
      " [0.33659059 0.87075155 0.97572636 0.81782695 0.64041069]\n",
      " [0.29516603 0.85453102 0.97089246 0.32829469 0.18191917]\n",
      " [0.72584118 0.4935642  0.46677159 0.84689011 0.56648909]\n",
      " [0.93868169 0.41185562 0.33496675 0.98017969 0.1782531 ]] [2 0 2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # avoids occupying full memory of GPU\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(training_iterator.initializer) # initialize the iterator \n",
    "    step = 0 # record the steps\n",
    "    try:\n",
    "        while(True):\n",
    "            x_, y_ = sess.run([x_input, y_label])\n",
    "            step += 1\n",
    "            print(\"{} batch - {} examples\".format(step, len(y_)))\n",
    "            print(x_, y_)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Above is the basic mechanics for using dataset and iterator to consume data. \n",
    "* The tf.data API provides compact methods to consume data and you can check following link for more comprehensive tutorials.\n",
    "* [Importing Data](https://www.tensorflow.org/guide/datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build basic model\n",
    "* In this part, we will introduce two methods to build a basic model which has one fully connected layer. \n",
    "* Here we guide you to use low level and high level method to construct it. \n",
    "* Although high level method provides compact utilities in tf.layers, it is better to understand the concepts of deep learning model using low level method in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting \n",
    "feature_dims = 784 # example with 784 features\n",
    "neurons = 1024 # fully connected layer with 1024 neurons\n",
    "classes = 10 # 10 classes classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low level\n",
    "* Construct the layers in neural network from scratch.\n",
    "* Define weights and bias as trainable variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(x_inputs, out_dim, name='fc'):\n",
    "    \"\"\" Low level method\n",
    "        x_inputs: a batch examples [batch_size, feature_dims]\n",
    "        out_dim: neurons in this layer.\n",
    "    \"\"\" \n",
    "    in_dim = x_inputs.shape[-1] # feature_dims\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        weights = tf.get_variable(\"weights\", shape=[in_dim, out_dim])\n",
    "        bias = tf.get_variable(\"bias\", shape=[out_dim])\n",
    "        out = tf.matmul(x_inputs, weights) + bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Output tensor]\n",
      "Tensor(\"fc/add:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"logits/add:0\", shape=(?, 10), dtype=float32)\n",
      "\n",
      "[Variables] \n",
      "<tf.Variable 'fc/weights:0' shape=(784, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'fc/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'logits/weights:0' shape=(1024, 10) dtype=float32_ref>\n",
      "<tf.Variable 'logits/bias:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, feature_dims])\n",
    "fc = fully_connected_layer(x, neurons, \"fc\")\n",
    "out = fully_connected_layer(fc, classes, \"logits\")\n",
    "print(\"[Output tensor]\", fc, out, sep=\"\\n\")\n",
    "print(\"\\n[Variables] \", *tf.trainable_variables(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level\n",
    "* Construct the layers in neural network using tf.layers.\n",
    "* A high level API provided by TensorFlow.\n",
    "* It contains a lot of useful methods and arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Output tensor]\n",
      "Tensor(\"fc/Relu:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"logits/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "\n",
      "[Variables] \n",
      "<tf.Variable 'fc/kernel:0' shape=(784, 1024) dtype=float32_ref>\n",
      "<tf.Variable 'fc/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "<tf.Variable 'logits/kernel:0' shape=(1024, 10) dtype=float32_ref>\n",
      "<tf.Variable 'logits/bias:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, feature_dims])\n",
    "fc = tf.layers.dense(x, neurons, activation=tf.nn.relu, name=\"fc\")\n",
    "out = tf.layers.dense(fc, classes, \n",
    "                      activation=tf.nn.softmax, name=\"logits\")\n",
    "print(\"[Output tensor]\", fc, out, sep=\"\\n\")\n",
    "print(\"\\n[Variables] \", *tf.trainable_variables(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model Walkthrough\n",
    "1. Build a Graph that:\n",
    "    * Define dataset and iterator\n",
    "    * Build the model\n",
    "    * Define the loss\n",
    "    * Define the optimizer\n",
    "    * Other tensors or operations you need (optional)\n",
    "2. Execute a session to:\n",
    "    * Initialize the variables\n",
    "    * Run the target tensors and operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## template\n",
    "with tf.Graph().as_default() as g:\n",
    "    \"\"\" Define dataset and iterator \"\"\"\n",
    "    with tf.name_scope(\"data\"):\n",
    "        pass\n",
    "    \n",
    "    \"\"\" Build the model \"\"\"\n",
    "    with tf.name_scope(\"model\"):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Define the loss \"\"\"\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        pass\n",
    "    \n",
    "    \"\"\" Define the optimizer \"\"\"\n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        pass\n",
    "    \n",
    "    \"\"\" Other tensors or operations you need \"\"\"\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        pass\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    \"\"\" Initialize the variables \"\"\"\n",
    "    \"\"\" Run the target tensors and operations \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec\n",
    "* Word2Vec is a computationally-efficient model that learns to embed words into vectors. The goal is to map words that have similar meanings close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why represent words as vectors?\n",
    "* When dealing with words, a straightforward way would be treating each word as discrete symbols. \n",
    "* For instance, cat as 2 and dog as 1. However, these symbols carry no information about the original word, making it impossible for us to infer the relationship between cats and dogs (both are four-legged animals and both are pets) based on the symbols alone.\n",
    "* Hence, to successfully learn the relationship between them, we might need a large amount of training data.\n",
    "* On the other hand, Vector space models (VSMs) which represent words as vectors can help overcome these obstacles. \n",
    "* This is based on a key observation that semantically similar words are often used interchangeably in different contexts. \n",
    "* For example, the words cat and dog may both appear in a context \"___ is my favorate pet.\" When feeding cat and dog into the NN to predict their nearby words, these two words will be likely to share the same/similar hidden representation in order to predict the same/similar nearby words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-Gram and CBOW\n",
    "* Word2Vec comes in two variants Skip-Gram and CBOW (Continuous Bag-Of-Words). Algorithmically, these models are similar. \n",
    "\n",
    "### <a name='BackCBOW'>CBOW</a>\n",
    "* [CBOW](#CBOW) predicts the target words using its neighborhood(context) whereas Skip-Gram does the inverse, which is to predict context words from the target words. \n",
    "* For example, given the sentence the quick brown fox jumped over the lazy dog. Defining the context words as the word to the left and right of the target word, CBOW will be trained on the dataset:\n",
    "    * ([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox)...\n",
    "* CBOW tries to predict the target word quick from the context words in brackets [the, brown], and predict brown from [quick, fox] and so on. \n",
    "* CBOW smoothes over a lot of the distributional information (by treating an entire context as one example). For the most part, this turns out to be a useful thing for smaller datasets. \n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/Cbow.png' width='300'>\n",
    "\n",
    "### <a name='BackSG'>Skip-Gram</a>\n",
    "* [Skip-Gram](#SG), the dataset becomes\n",
    "    * (quick, the), (quick, brown), (brown, quick), (brown, fox), ...\n",
    "* where Skip-Gram predicts the context word the, brown with the target word quick. \n",
    "* Skip-Gram treats each context-target pair as a new observation and is shown to be able to capture the semantics better when we have a large dataset.\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/Skip-gram.png' width='300'>\n",
    "\n",
    "* Note that the tasks described above are only used to train the neural network, we don’t use the neural network for the task we trained it on. What we want is the weights of the hidden layer, the \"embedding matrix\".\n",
    "* For the rest of the tutorial, we will focus on the Skip-Gram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='BackNCE'>Noise Constrative Estimation</a>\n",
    "* More information aboit [NCE](#NCE)\n",
    "* Before we start implementing a skip-gram model, we want to introduce an important techniques that reduce the computing efforts. It is called noise constrative estimation.\n",
    "* Let's motivate this idea by a naive method. If we want to create a skip-gram model, we can use the following snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive idea, this is not runnable.\n",
    "\n",
    "vocabulary_size = 10000\n",
    "embedding_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    center_words = tf.placeholder(tf.int32, [batch_size])\n",
    "    target_words = tf.placeholder(tf.int32, [batch_size])\n",
    "    \n",
    "    encode_matrix = tf.get_variable(\"encoder\",\n",
    "                                    shape=[vocabulary_size, embedding_size])\n",
    "    decode_matrix = tf.get_variable(\"decoder\",\n",
    "                                    shape=[embedding_size, vocabulary_size])\n",
    "    \n",
    "    embedding = tf.matmul(center_words, encode_matrix)\n",
    "    logits = tf.matmul(embedding, decode_matrix)\n",
    "\n",
    "    output = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/softmax-nplm.png' width='300'>\n",
    "* As we can see, it has a large number of parameters in the network and the softmax layer is a computationally intensive task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any solution to solve it?\n",
    "* NCE comes to rescue the problem of softmax.\n",
    "* Like most neural networks, a Skip-Gram model is trained using the maximum likelihood(ML) principle:\n",
    "$$\\arg\\min_{\\Theta}\\sum_{i=1}^{N}{-\\log\\mathrm{P}(\\boldsymbol{y}^{(i)}\\,|\\,\\boldsymbol{x}^{(i)},\\Theta)}$$\n",
    "* In a multiclass task where $y=1,\\cdots,V$(V being the vocabulary size) we usually assume\n",
    "$$\\Pr(y\\,|\\,\\boldsymbol{x})\\sim\\mathrm{Categorical}(y\\,|\\,\\boldsymbol{x};\\boldsymbol{\\rho})=\\prod_{i=1}^{V}\\rho_{i}^{1(y;\\,y=i)}.$$\n",
    "* It is natural to use $V$ Softmax units in the output layer. That is, the activation $a_i^{(L)}$ of each unit at the last layer(layer $L$) $z_i^{(L)}$ outputs one dimension of the softmax function, a generalization of the logistic sigmoid:\n",
    "$$a_i^{(L)}=\\rho_i=\\mathrm{softmax}(\\boldsymbol{z}^{(L)})_{i}=\\frac{\\exp(z_{i}^{(L)})}{\\sum_{j=1}^{{\\color{red}V}}\\exp(z_{j}^{(L)})}.$$\n",
    "* The objective function then becomes:\n",
    "$$\\arg\\min_{\\Theta}\\sum_{i}-\\log\\prod_{j}\\left(\\frac{\\exp(z_{j}^{(L)})}{\\sum_{k=1}^{{\\color{red}V}}\\exp(z_{k}^{(L)})}\\right)^{1(y^{(i)};y^{(i)}=j)}=\\arg\\min_{\\Theta}\\sum_{i}\\left[-z_{y^{(i)}}^{(L)}+\\log\\sum_{k=1}^{{\\color{red}V}}\\exp(z_{k}^{(L)})\\right]$$\n",
    "* On the other hand, for feature learning in word2vec we do not need a full probabilistic model. \n",
    "* The CBOW and skip-gram models are instead trained using a binary classification objective (logistic regression) to discriminate the real target words $w_{t}$ from $k$ imaginary (noise) words $\\tilde{w}$, in the same context.\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/softmax-nplm.png' width='300'>\n",
    "* Since we are sampling from two distributions, the correct word is sampled from the true distribution $P$ according to the context c and noise words are sampled from $Q$, which is a noise distribution, in practice, it is said to be a uniform distribution\n",
    "* The cost function finally transform to:\n",
    "$$C(\\theta) = - \\sum_{i=1}^{V} [log\\frac{ exp(\\,z_{i}^{(L)}\\,) }{ exp(\\,z_{i}^{(L)}\\,) + kQ(\\boldsymbol{w})} + logP(1 - \\frac{ exp(\\,z_{i}^{(L)}\\,) }{ exp(\\,z_{i}^{(L)}\\,) + kQ(\\boldsymbol{w})} ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Skip gram model with NCE loss\n",
    "### The Dataset\n",
    "* The dataset we use is text8, which is the first 100 MB of cleaned text of the English Wikipedia dump on Mar. 3, 2006. While 100MB is not enough to train really good embeddings, we can still see some interesting relations. \n",
    "* Splitting the text by blank space, we can find that there are 17,005,207 tokens in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training data\n",
    "* To generate batches for training, several functions defined below are used. \n",
    "* First, we read the data into the memory and build the vocabulary using a number of most commonly seen words. Meanwhile, we build two dictionaries, a dictionary that translates words to indices and another which does the reverse. \n",
    "* Then, for every word in the text selected as the center word, pair them with one of the context words. \n",
    "* Finally, a python generator which generates a batch of pairs of center-target pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded the file data/text8.zip\n"
     ]
    }
   ],
   "source": [
    "# Download the data.\n",
    "DOWNLOAD_URL = 'http://mattmahoney.net/dc/'\n",
    "DATA_FOLDER = \"data\"\n",
    "FILE_NAME = \"text8.zip\"\n",
    "EXPECTED_BYTES = 31344016\n",
    "\n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "def download(file_name, expected_bytes):\n",
    "    \"\"\" Download the dataset text8 if it's not already downloaded \"\"\"\n",
    "    local_file_path = os.path.join(DATA_FOLDER, file_name)\n",
    "    if os.path.exists(local_file_path):\n",
    "        print(\"Dataset ready\")\n",
    "        return local_file_path\n",
    "    file_name, _ = urllib.request.urlretrieve(\n",
    "      os.path.join(DOWNLOAD_URL, file_name), local_file_path)\n",
    "    file_stat = os.stat(local_file_path)\n",
    "    if file_stat.st_size == expected_bytes:\n",
    "        print('Successfully downloaded the file', file_name)\n",
    "    else:\n",
    "        raise Exception(\n",
    "              'File ' + file_name +\n",
    "              ' might be corrupted. You should try downloading it with a browser.')\n",
    "    return local_file_path    \n",
    "    \n",
    "make_dir(DATA_FOLDER)\n",
    "file_path = download(FILE_NAME, EXPECTED_BYTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 17005207\n"
     ]
    }
   ],
   "source": [
    "# Read the data into a list of strings.\n",
    "def read_data(file_path):\n",
    "    \"\"\" Read data into a list of tokens\"\"\"\n",
    "    with zipfile.ZipFile(file_path) as f:\n",
    "        # tf.compat.as_str() converts the input into the string\n",
    "        data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "    return data\n",
    "\n",
    "vocabulary = read_data(file_path)\n",
    "print('Data size', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# Build the dictionary and replace rare words with UNK token.\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\" Create two dictionaries and count of occuring words\n",
    "        - word_to_id: map of words to their codes\n",
    "        - id_to_word: maps codes to words (inverse word_to_id)\n",
    "        - count: map of words to count of occurrences\n",
    "    \"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    word_to_id = dict() # (word, id)\n",
    "    # record word id\n",
    "    for word, _ in count:\n",
    "        word_to_id[word] = len(word_to_id)\n",
    "    id_to_word = dict(zip(word_to_id.values(), word_to_id.keys())) # (id, word)\n",
    "    return word_to_id, id_to_word, count\n",
    "\n",
    "def convert_words_to_id(words, dictionary, count):\n",
    "    \"\"\" Replace each word in the dataset with its index in the dictionary\"\"\"\n",
    "    data_w2id = []\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data_w2id.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    return data_w2id, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Filling 4 global variables:\n",
    "# data_w2id - list of codes (integers from 0 to vocabulary_size-1).\n",
    "              This is the original text but words are replaced by their codes\n",
    "# count - map of words(strings) to count of occurrences\n",
    "# word_to_id - map of words(strings) to their codes(integers)\n",
    "# id_to_word - maps codes(integers) to words(strings)\n",
    "\"\"\"\n",
    "\n",
    "vocabulary_size = 50000\n",
    "word_to_id, id_to_word, count = build_dataset(vocabulary, vocabulary_size)\n",
    "data_w2id, count = convert_words_to_id(vocabulary, word_to_id, count)\n",
    "del vocabulary  # reduce memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
      "Sample data: [5234, 3084, 12, 6, 195, 2, 3134, 46, 59, 156]\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
     ]
    }
   ],
   "source": [
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data: {}'.format(data_w2id[:10]))\n",
    "print([id_to_word[i] for i in data_w2id[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def generate_sample(center_words, context_window_size):\n",
    "    \"\"\" Form training pairs according to the skip-gram model.\"\"\"\n",
    "    for idx, center in enumerate(center_words):\n",
    "        context = random.randint(1, context_window_size)\n",
    "        # get a random target before the center word\n",
    "        for target in center_words[max(0, idx - context) : idx]:\n",
    "            yield center, target\n",
    "        # get a random target after the center word\n",
    "        for target in center_words[idx + 1 : idx + context + 1]:\n",
    "            yield center, target\n",
    "\n",
    "def batch_generator(data, skip_window, batch_size):\n",
    "    \"\"\" Group a numeric stream into batches and yield them as Numpy arrays.\"\"\"\n",
    "    single_gen = generate_sample(data, skip_window)\n",
    "    while True:\n",
    "        center_batch = np.zeros(batch_size, dtype=np.int32)\n",
    "        target_batch = np.zeros([batch_size, 1], dtype=np.int32)\n",
    "        for idx in range(batch_size):\n",
    "            center_batch[idx], target_batch[idx] = next(single_gen)\n",
    "        yield center_batch, target_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some training settings\n",
    "training_steps = 1000\n",
    "skip_step = 100\n",
    "graph_dir = \"graphs/word2vec_simple\"\n",
    "ckpt_dir = \"checkpoints/word2vec_simple\"\n",
    "\n",
    "## some hyperparameters\n",
    "batch_size = 128\n",
    "embed_size = 128\n",
    "num_sampled = 64\n",
    "learning_rates = 1.0\n",
    "\n",
    "## geneartor for `tf.data.Dataset`\n",
    "def gen():\n",
    "    \"\"\" Return a python generator that generates batches. \"\"\"\n",
    "    yield from batch_generator(data_w2id, 2, batch_size)\n",
    "\n",
    "## model\n",
    "def word2vec(dataset):\n",
    "    \n",
    "    \"\"\" 1. Build the graph\"\"\" \n",
    "    with tf.name_scope(\"data\"):\n",
    "        # one_shot_iterator doesn't need to be initialized\n",
    "        iterator = dataset.make_one_shot_iterator() \n",
    "        # get the input and output\n",
    "        center_words, target_words = iterator.get_next() \n",
    "    \n",
    "    with tf.name_scope('embed'):\n",
    "        embedding_matrix = tf.get_variable(\"embedding_matrix\",\n",
    "                                           shape=[vocabulary_size, embed_size])\n",
    "        embedding = tf.nn.embedding_lookup(embedding_matrix,\n",
    "                                           center_words, name='embedding')\n",
    "        \n",
    "    with tf.name_scope('loss'):\n",
    "        initializer = tf.truncated_normal_initializer(stddev=1.0 / (embed_size ** 0.5))\n",
    "        nce_weight = tf.get_variable('nce_weight',\n",
    "                                     shape=[vocabulary_size, embed_size],\n",
    "                                     initializer=initializer)\n",
    "        nce_bias = tf.get_variable('nce_bias', shape=[vocabulary_size],\n",
    "                                   initializer=tf.zeros_initializer)\n",
    "\n",
    "        # define loss function to be NCE loss function\n",
    "        loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n",
    "                                            biases=nce_bias, \n",
    "                                            labels=target_words, \n",
    "                                            inputs=embedding, \n",
    "                                            num_sampled=num_sampled, \n",
    "                                            num_classes=vocabulary_size), name='loss')\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rates).minimize(loss)\n",
    "    \n",
    "    ## store checkpoints\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    \"\"\" 2. Execute a session \"\"\"\n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.allow_growth = True  # avoids occupying full memory of GPU\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "\n",
    "        # if that checkpoint exists, restore from checkpoint\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # we use this to calculate late average loss in the last SKIP_STEP steps\n",
    "        total_loss = 0.0 \n",
    "        writer = tf.summary.FileWriter(graph_dir, sess.graph)\n",
    "\n",
    "        for index in range(1, training_steps+1):\n",
    "            try:\n",
    "                loss_batch, _ = sess.run([loss, optimizer])\n",
    "                total_loss += loss_batch\n",
    "                if index % skip_step == 0:\n",
    "                    print('Average loss at step {}: {:5.1f}'.format(\n",
    "                        index, total_loss / skip_step))\n",
    "                    total_loss = 0.0\n",
    "                    saver.save(sess,\n",
    "                               os.path.join(ckpt_dir, \"model\"),\n",
    "                               index)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 100: 232.4\n",
      "Average loss at step 200: 187.3\n",
      "Average loss at step 300: 166.2\n",
      "Average loss at step 400: 152.9\n",
      "Average loss at step 500: 145.5\n",
      "Average loss at step 600: 131.5\n",
      "Average loss at step 700: 118.0\n",
      "Average loss at step 800: 115.4\n",
      "Average loss at step 900: 108.5\n",
      "Average loss at step 1000: 104.2\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(gen, (tf.int32, tf.int32),\n",
    "                                         (tf.TensorShape([batch_size]),\n",
    "                                          tf.TensorShape([batch_size, 1])))\n",
    "word2vec(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "## 1. Learning the XOR\n",
    "### Problem Definition\n",
    "* Build a model to challenge this task.\n",
    "* Input: binary data of shape=[2]\n",
    "* Output: xor result of this input, shape=[1]\n",
    "### Requirements\n",
    "* Show the code of graph and session you build.\n",
    "* Use low level API method (define the weights and bias from scratch like above)\n",
    "* Show the accuracy of these 4 examples (it should be 100%)\n",
    "* Show the values of weights and bias you used.\n",
    "### Notes\n",
    "* The model architecture are not constrainted.\n",
    "* It is an easy nonlinear function that neural network can fit rapidly.\n",
    "\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/xor.png' width='200'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# xor task\n",
    "graph_dir = \"graphxor\"\n",
    "\n",
    "xor_data = np.array([[1, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 1],\n",
    "                    [0, 0]])\n",
    "xor_label = np.array([[1], [1], [0], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:\n",
      " [[ 0.9515214   0.7999611   0.09289098]\n",
      " [-0.9688332   0.58291626  0.13160276]] \n",
      "W2:\n",
      " [[-0.9601724 ]\n",
      " [-0.13457823]\n",
      " [-0.06717491]] \n",
      ":b1\n",
      " [0. 0. 0.] \n",
      "b2:\n",
      " [0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    x_input = tf.placeholder(tf.float32, [None, 2])\n",
    "    y_label = tf.placeholder(tf.float32, [None, 1])\n",
    "  \n",
    "    \"\"\"add code\"\"\"\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 3], -1.0, 1.0))\n",
    "    b1 = tf.Variable(tf.zeros([3]))\n",
    "    O = tf.nn.sigmoid(tf.matmul(x_input, W1) + b1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_uniform([3, 1], -1.0, 1.0))\n",
    "    b2 = tf.Variable(tf.zeros([1]))\n",
    "    y = tf.nn.sigmoid(tf.matmul(O, W2) + b2)\n",
    "    \n",
    "    cost = tf.reduce_sum(tf.square(y_label - y), reduction_indices=[0])\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "    \n",
    "    correcct_prediction = abs(y_label - y) < 0.5\n",
    "    cast = tf.cast(correcct_prediction, \"float\")\n",
    "    accuracy = tf.reduce_mean(cast)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(graph_dir, tf.get_default_graph())\n",
    "    \"\"\"add code\"\"\"\n",
    "    # start building your model and meet the requirements\n",
    "    # from here\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # start run the seesion and meet the requrements\n",
    "    # from here \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    Ecoches = 5000\n",
    "    weigh1, weigh2, bias1, bias2 = sess.run([W1,\n",
    "                                          W2,\n",
    "                                          b1, b2])\n",
    "    print(\"W1:\\n {} \\nW2:\\n {} \\n:b1\\n {} \\nb2:\\n {}\".format(weigh1, weigh2, bias1, bias2))\n",
    "    for i in range(Ecoches):\n",
    "        sess.run(train_step, feed_dict={x_input : xor_data, y_label :xor_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "yy, accuracy = sess.run([y, accuracy], feed_dict={x_input: xor_data, y_label: xor_label})\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNIST - Digits classification\n",
    "### Problem Definition\n",
    "* Build a fully connected network to challenge this task.\n",
    "* Input: an image of shape=[784]\n",
    "* Output: a digit of this image, shape=[10]\n",
    "### Requirements\n",
    "* Show the code of graph and session you build.\n",
    "* Use tf.data.Dataset and tf.data.Iterator to extract data.\n",
    "* Use low level API method to build the model (define the weights and bias from scratch like above).\n",
    "* The accuracy on mnist.test should be at least 95%.\n",
    "### Notes\n",
    "* the hyperparameters are not constrainted (e.g. num_neurons_in_one_layer, how_many_layers, learning_rates, training_epochs, * batch_size)\n",
    "* the optimizer are not constrainted.\n",
    "* mnist.train is all you can use to train the model. mnist.validation are just used to be validated.\n",
    "\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/fc.png' width='500'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-e70db4c1b96c>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/epl002/DL/env-name/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/epl002/DL/env-name/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/epl002/DL/env-name/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/epl002/DL/env-name/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/epl002/DL/env-name/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/epl002/DL/env-name/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# load mnist data\n",
    "mnist = input_data.read_data_sets(\"data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 55000\n",
      "validation data size: 5000\n",
      "testing data size: 10000\n",
      "Shape of image: (784,)\n",
      "Shape of label: (10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data size: {}\".format(mnist.train.num_examples))\n",
    "print(\"validation data size: {}\".format(mnist.validation.num_examples))\n",
    "print(\"testing data size: {}\".format(mnist.test.num_examples))\n",
    "\n",
    "print(\"Shape of image: {}\".format(mnist.train.images[0].shape))\n",
    "print(\"Shape of label: {}\".format(mnist.train.labels[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(5):\n",
    "    plt.subplot(n, n, i+1)\n",
    "    plt.imshow(mnist.train.images[i].reshape(28,28), cmap='gray')\n",
    "    plt.title(np.argmax(mnist.train.labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/epl002/DL/env-name/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:359: UserWarning: An unusually high number of `Iterator.get_next()` calls was detected. This often indicates that `Iterator.get_next()` is being called inside a training loop, which will cause gradual slowdown and eventual resource exhaustion. If this is the case, restructure your code to call `next_element = iterator.get_next()` once outside the loop, and use `next_element` as the input to some computation that is invoked inside the loop.\n",
      "  warnings.warn(GET_NEXT_CALL_WARNING_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9237\n",
      "0.9483\n",
      "0.9636\n"
     ]
    }
   ],
   "source": [
    "batch_size = 7\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "    ys = tf.placeholder(tf.float32, [None, 10])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "\n",
    "    W_conv1 = weight_variable([5,5, 1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    W_conv2 = weight_variable([5,5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "    prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),reduction_indices=[1]))# loss\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(graph_dir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((mnist.train.images, mnist.train.labels))\n",
    "    training_dataset = training_dataset.batch(batch_size)\n",
    "    training_iterator = training_dataset.make_initializable_iterator()\n",
    "    sess.run(training_iterator.initializer)\n",
    "    \n",
    "    for i in range(3000):\n",
    "        x_input, y_label = training_iterator.get_next()\n",
    "        x_, y_ = sess.run([x_input, y_label])\n",
    "        sess.run(train_step, feed_dict={xs: x_, ys: y_, keep_prob: 0.5})\n",
    "        if i % 1000 == 0:\n",
    "            print(compute_accuracy(mnist.test.images, mnist.test.labels))\n",
    "    print(compute_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='SG'>Skip-gram</a>\n",
    "* 在自然語言中，許多單字的表達是由他們的tf-idf分數決定的\n",
    "* 這些分數告訴我們一個單字在一個文本中的相對重要性，但他們並沒有告訴我們單詞的語義\n",
    "* Word2vec是一類的神經網路模型，再給定無標籤的語料庫情況下，為語料庫中的單詞產生一個能表達語意的向量\n",
    "* input:\n",
    "    * 一個單詞$w_{i}$\n",
    "* output:\n",
    "    * 上下文的窗口大小為$C$\n",
    "    * $w_{i}$的上下文${w_{O,1},...,w_{O,C}}$\n",
    "* Example:\n",
    "    * 句子: I drive my car to the store.\n",
    "    * 如果input是\"car\"\n",
    "    * output:{“I”, “drive”, “my”, “to”, “the”, “store”}\n",
    "<img src='https://nthu-datalab.github.io/ml/labs/10_TensorFlow101_Word2Vec/assets/Skip-gram.png' width='300'>\n",
    "-------------------\n",
    "* [Reference](https://blog.csdn.net/u010665216/article/details/78721354)\n",
    "* [Go to Skip-gram](#BackSG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='CBOW'>CBOW</a>\n",
    "* Continuous Bag of Words\n",
    "* CBOW與skip-gram相反\n",
    "* input為$w_{0}, w_{1}, ..., w_{j}$\n",
    "* output為$w_{j}$\n",
    "-------------------\n",
    "* [Reference](https://blog.csdn.net/u010665216/article/details/78721354)\n",
    "* [Go to CBOW](#BackCBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='NCE'>Noise Contrastive estimation</a>\n",
    "* 噪音對比估計（NCE）作為一個比重要性採樣方法（IS）更穩定的採樣方法提出\n",
    "* NCE 並沒有試圖直接預測一個詞的機率，而是用一個輔助性的損失函數來同時最大化正確詞的機率\n",
    "* 將預測正確詞的任務簡化到一個二元分類任務，其中模型試圖從噪音樣本中區分正確、真實的數據\n",
    "<img src='https://i2.kknews.cc/SIG=g9ik31/s68000933op14s7s4s3.jpg' width='300'>\n",
    "-------------------\n",
    "* [Reference](https://kknews.cc/zh-tw/news/6xqo2l.html)\n",
    "* [Go to NCE](#BackNCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
